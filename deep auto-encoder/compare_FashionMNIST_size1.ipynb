{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compare_FashionMNIST_size1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "25dJ4RGMWqiH",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4RJPMel7XBOZ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 500)\n",
        "        \n",
        "        #add\n",
        "        #self.fc2 = nn.Linear(1000, 500)\n",
        "        self.fc3 = nn.Linear(500, 250)\n",
        "        self.fc4 = nn.Linear(250, 30)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = torch.sigmoid(out)\n",
        "        #out = self.fc2(out)\n",
        "        #out = torch.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 250)\n",
        "        self.fc2 = nn.Linear(250, 500)\n",
        "        #self.fc3 = nn.Linear(500, 1000)\n",
        "        self.fc4 = nn.Linear(500, 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.fc1(x)\n",
        "        \n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        out = self.fc2(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        #out = self.fc3(out)\n",
        "        #out = torch.sigmoid(out)\n",
        "        out = self.fc4(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aLVAzHlAVQPG",
        "colab": {}
      },
      "source": [
        "from torch.optim.optimizer import Optimizer, required\n",
        "import copy\n",
        "\n",
        "class AccSGD(Optimizer):\n",
        "    r\"\"\"Implements the algorithm proposed in https://arxiv.org/pdf/1704.08227.pdf, which is a provably accelerated method \n",
        "    for stochastic optimization. This has been employed in https://openreview.net/forum?id=rJTutzbA- for training several \n",
        "    deep learning models of practical interest. This code has been implemented by building on the construction of the SGD \n",
        "    optimization module found in pytorch codebase.\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): learning rate (required)\n",
        "        kappa (float, optional): ratio of long to short step (default: 1000)\n",
        "        xi (float, optional): statistical advantage parameter (default: 10)\n",
        "        smallConst (float, optional): any value <=1 (default: 0.7)\n",
        "    Example:\n",
        "        >>> from AccSGD import *\n",
        "        >>> optimizer = AccSGD(model.parameters(), lr=0.1, kappa = 1000.0, xi = 10.0)\n",
        "        >>> optimizer.zero_grad()\n",
        "        >>> loss_fn(model(input), target).backward()\n",
        "        >>> optimizer.step()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=required, kappa = 1000.0, xi = 10.0, smallConst = 0.7, weight_decay=0):\n",
        "        defaults = dict(lr=lr, kappa=kappa, xi=xi, smallConst=smallConst,\n",
        "                        weight_decay=weight_decay)\n",
        "        super(AccSGD, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(AccSGD, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\" Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            large_lr = (group['lr']*group['kappa'])/(group['smallConst'])\n",
        "            Alpha = 1.0 - ((group['smallConst']*group['smallConst']*group['xi'])/group['kappa'])\n",
        "            Beta = 1.0 - Alpha\n",
        "            zeta = group['smallConst']/(group['smallConst']+Beta)\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = p.grad.data\n",
        "                if weight_decay != 0:\n",
        "                    d_p.add_(weight_decay, p.data)\n",
        "                param_state = self.state[p]\n",
        "                if 'momentum_buffer' not in param_state:\n",
        "                    param_state['momentum_buffer'] = copy.deepcopy(p.data)\n",
        "                buf = param_state['momentum_buffer']\n",
        "                buf.mul_((1.0/Beta)-1.0)\n",
        "                buf.add_(-large_lr,d_p)\n",
        "                buf.add_(p.data)\n",
        "                buf.mul_(Beta)\n",
        "\n",
        "                p.data.add_(-group['lr'],d_p)\n",
        "                p.data.mul_(zeta)\n",
        "                p.data.add_(1.0-zeta,buf)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rpLq0tmvMfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojrIUslLvMfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1UYDhZjdcf7W",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec    \n",
        "import os\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "\n",
        "device = torch.device(\"cuda:3\")\n",
        "\n",
        "\n",
        "def MN_SGD(batch_size, nEpoch, lr):\n",
        "#batch_size = 32\n",
        "\n",
        "# dataset construction\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # convert to tensor\n",
        "        transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector\n",
        "        ])\n",
        "\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./data/FashionMNIST'\n",
        "        ,train=True\n",
        "        ,download=True\n",
        "        ,transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    enc_dim = 30\n",
        "    image_dim = 784  # [flattened]\n",
        "\n",
        "    # construct the encoder, decoder and optimiser\n",
        "    enc = Encoder(image_dim).to(device)\n",
        "    dec = Decoder(enc_dim).to(device)\n",
        "    #optimizer = optim.Adam(chain(enc.parameters(), dec.parameters()), lr=1e-3)\n",
        "    #optimizer = AccSGD(chain(enc.parameters(), dec.parameters()), lr=0.025, kappa = 100.0, xi = 2.5)\n",
        "    optimizer = optim.SGD(chain(enc.parameters(), dec.parameters()), lr)\n",
        "\n",
        "    # training loop\n",
        "    loss_all2 = []\n",
        "    for epoch in range(nEpoch):\n",
        "        losses = []\n",
        "        trainloader = tqdm(train_loader)\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            if i * batch_size >= 10000:\n",
        "                break\n",
        "            else:\n",
        "                inputs, _ = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                z = enc(inputs)\n",
        "                outputs = dec(z)\n",
        "\n",
        "                loss = F.mse_loss(outputs, inputs, size_average=False) / inputs.shape[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # keep track of the loss and update the stats\n",
        "                losses.append(loss.item())\n",
        "                trainloader.set_postfix(loss=np.mean(losses), epoch=epoch)\n",
        "        loss_all2.append(np.sqrt(np.mean(losses)))\n",
        "    return loss_all2\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egSQs5psvMfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MN_ASGD(batch_size, nEpoch, lr, kappa, xi):\n",
        "#batch_size = 32\n",
        "\n",
        "# dataset construction\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # convert to tensor\n",
        "        transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector\n",
        "        ])\n",
        "\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./data/FashionMNIST'\n",
        "        ,train=True\n",
        "        ,download=True\n",
        "        ,transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    enc_dim = 30\n",
        "    image_dim = 784  # [flattened]\n",
        "\n",
        "    # construct the encoder, decoder and optimiser\n",
        "    enc = Encoder(image_dim).to(device)\n",
        "    dec = Decoder(enc_dim).to(device)\n",
        "    #optimizer = optim.Adam(chain(enc.parameters(), dec.parameters()), lr=1e-3)\n",
        "    #optimizer = AccSGD(chain(enc.parameters(), dec.parameters()), lr=0.025, kappa = 100.0, xi = 2.5)\n",
        "    optimizer = AccSGD(chain(enc.parameters(), dec.parameters()), lr, kappa, xi)\n",
        "\n",
        "    # training loop\n",
        "    loss_all2 = []\n",
        "    for epoch in range(nEpoch):\n",
        "        losses = []\n",
        "        trainloader = tqdm(train_loader)\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            if i * batch_size >= 10000:\n",
        "                break\n",
        "            else:\n",
        "                    \n",
        "                inputs, _ = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                z = enc(inputs)\n",
        "                outputs = dec(z)\n",
        "\n",
        "                loss = F.mse_loss(outputs, inputs, size_average=False) / inputs.shape[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # keep track of the loss and update the stats\n",
        "                losses.append(loss.item())\n",
        "                trainloader.set_postfix(loss=np.mean(losses), epoch=epoch)\n",
        "        loss_all2.append(np.sqrt(np.mean(losses)))\n",
        "    return loss_all2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ggj8T6EvMfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MN_NAG(batch_size, nEpoch, lr, momentum):\n",
        "\n",
        "# dataset construction\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # convert to tensor\n",
        "        transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector\n",
        "        ])\n",
        "\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./data/FashionMNIST'\n",
        "        ,train=True\n",
        "        ,download=True\n",
        "        ,transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    enc_dim = 30\n",
        "    image_dim = 784  # [flattened]\n",
        "\n",
        "    # construct the encoder, decoder and optimiser\n",
        "    enc = Encoder(image_dim).to(device)\n",
        "    dec = Decoder(enc_dim).to(device)\n",
        "    #optimizer = optim.Adam(chain(enc.parameters(), dec.parameters()), lr=1e-3)\n",
        "    #optimizer = AccSGD(chain(enc.parameters(), dec.parameters()), lr=0.025, kappa = 100.0, xi = 2.5)\n",
        "    optimizer = optim.SGD(chain(enc.parameters(), dec.parameters()), lr, momentum, nesterov = True)\n",
        "\n",
        "    # training loop\n",
        "    loss_all2 = []\n",
        "    for epoch in range(nEpoch):\n",
        "        losses = []\n",
        "        trainloader = tqdm(train_loader)\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            if i * batch_size >= 10000:\n",
        "                break\n",
        "            else:\n",
        "                inputs, _ = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                z = enc(inputs)\n",
        "                outputs = dec(z)\n",
        "\n",
        "                loss = F.mse_loss(outputs, inputs, size_average=False) / inputs.shape[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # keep track of the loss and update the stats\n",
        "                losses.append(loss.item())\n",
        "                trainloader.set_postfix(loss=np.mean(losses), epoch=epoch)\n",
        "        loss_all2.append(np.sqrt(np.mean(losses)))\n",
        "    return loss_all2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P2ZzWg_vMfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MN_HB(batch_size, nEpoch, lr, momentum):\n",
        "\n",
        "# dataset construction\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # convert to tensor\n",
        "        transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector\n",
        "        ])\n",
        "\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./data/FashionMNIST'\n",
        "        ,train=True\n",
        "        ,download=True\n",
        "        ,transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    enc_dim = 30\n",
        "    image_dim = 784  # [flattened]\n",
        "\n",
        "    # construct the encoder, decoder and optimiser\n",
        "    enc = Encoder(image_dim).to(device)\n",
        "    dec = Decoder(enc_dim).to(device)\n",
        "    #optimizer = optim.Adam(chain(enc.parameters(), dec.parameters()), lr=1e-3)\n",
        "    #optimizer = AccSGD(chain(enc.parameters(), dec.parameters()), lr=0.025, kappa = 100.0, xi = 2.5)\n",
        "    optimizer = optim.SGD(chain(enc.parameters(), dec.parameters()), lr, momentum)\n",
        "\n",
        "    # training loop\n",
        "    loss_all2 = []\n",
        "    for epoch in range(nEpoch):\n",
        "        losses = []\n",
        "        trainloader = tqdm(train_loader)\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            if i * batch_size >= 10000:\n",
        "                break\n",
        "            else:\n",
        "                inputs, _ = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                z = enc(inputs)\n",
        "                outputs = dec(z)\n",
        "\n",
        "                loss = F.mse_loss(outputs, inputs, size_average=False) / inputs.shape[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # keep track of the loss and update the stats\n",
        "                losses.append(loss.item())\n",
        "                trainloader.set_postfix(loss=np.mean(losses), epoch=epoch)\n",
        "        loss_all2.append(np.sqrt(np.mean(losses)))\n",
        "    return loss_all2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KulVQkxvMfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "nEpoch = 30\n",
        "Batch_size = 1\n",
        "loss_SGD = MN_SGD(Batch_size, nEpoch, 0.00001*np.sqrt(10))\n",
        "loss_NAG = MN_NAG(Batch_size, nEpoch, 0.00002, 0.52)\n",
        "loss_HB = MN_HB(Batch_size, nEpoch, 0.00002, 0.5)\n",
        "loss_ASGD = MN_ASGD(Batch_size, nEpoch, 0.0001, 100, 0.25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARg1Nm4avMfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_init = max(loss_SGD[0], loss_NAG[0], loss_HB[0], loss_ASGD[0])\n",
        "# dif = np.zeros(4)\n",
        "# dif = loss_init * np.ones(4) - [loss_SGD[0], loss_NAG[0], loss_HB[0], loss_ASGD[0]]\n",
        "\n",
        "# loss_SGD = loss_SGD + dif[0]\n",
        "# loss_NAG = loss_NAG + dif[1]\n",
        "# loss_HB = loss_HB + dif[2]\n",
        "# loss_ASGD = loss_ASGD + dif[3]\n",
        "# loss_SGD[0] = loss_init\n",
        "# loss_NAG[0] = loss_init\n",
        "# loss_HB[0] = loss_init\n",
        "# loss_ASGD[0] = loss_init\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Comparison of different methods (FashionMNIST)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE lose')\n",
        "x = np.linspace(0, nEpoch, nEpoch)\n",
        "plt.plot(x, loss_SGD, label = 'SGD')\n",
        "plt.plot(x, loss_NAG, label = 'NAG')\n",
        "plt.plot(x, loss_HB, label = 'HB')\n",
        "plt.plot(x, loss_ASGD, label = 'AccSGD')\n",
        "plt.legend()\n",
        "plt.savefig('Compare(New dataset).png')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfS7kHNuvMfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}