{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNZBeETJ2FcM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Python\\Python27\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "try: \n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer\n",
    "\n",
    "try:\n",
    "    import torchtext\n",
    "except:\n",
    "    !pip install torchtext\n",
    "    \n",
    "try:\n",
    "    import spacy\n",
    "except:\n",
    "    !pip install spacy\n",
    "    \n",
    "try:\n",
    "    spacy.load('en')\n",
    "except:\n",
    "    !python -m spacy download en\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReQi-ETd2LRX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchbearer import Trial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCqcXwtV2ROm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(2,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x) \n",
    "        return out\n",
    "      \n",
    "model_HB = LinearRegression()\n",
    "model_NAG = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2yK0rHV2hk2"
   },
   "outputs": [],
   "source": [
    "k = 2**4\n",
    "\n",
    "w_ture = torch.rand(2,1)*5\n",
    "\n",
    "# generate training set\n",
    "pro = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "    torch.Tensor([2,1]), covariance_matrix=torch.Tensor([[1,0],[0,1/k]]))\n",
    "a = torch.zeros(500,2)\n",
    "b = torch.zeros(500,1)\n",
    "for i in range(500):\n",
    "    a[i] = pro.sample()\n",
    "    b[i] = a[i] @ w_ture   \n",
    "# generate testing set\n",
    "a_test = torch.zeros(500,2)\n",
    "b_test = torch.zeros(500,1)\n",
    "for i in range(500):\n",
    "    a_test[i] = pro.sample()\n",
    "    b_test[i] = a[i] @ w_ture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR_Ml05133pk"
   },
   "outputs": [],
   "source": [
    "def ave_loss_HB(lamada,m):\n",
    "  \n",
    "  losses = torch.Tensor([0])\n",
    "  \n",
    "  for i in range(100):\n",
    "    nEpoch = 10\n",
    "    model_HB = LinearRegression()\n",
    "    optimizer = optim.SGD(model_HB.parameters(), lr=lamada, momentum=m)\n",
    "    loss_func = nn.MSELoss()\n",
    "    for epoch in range(nEpoch):\n",
    "        for i in range(5): \n",
    "            optimizer.zero_grad()\n",
    "            b_hat = model_HB(a)\n",
    "            loss = loss_func(b_hat,b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    b_hat_test = model_HB(a_test)\n",
    "    loss_func_test = nn.MSELoss()\n",
    "    losses = losses + loss_func_test(b_test,b_hat_test)\n",
    "    losses = losses/100\n",
    "  \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olMecy5d4nxt"
   },
   "outputs": [],
   "source": [
    "def ave_loss_NAG(lamada,m):\n",
    "    losses = torch.Tensor([0])\n",
    "    for i in range(100):\n",
    "        nEpoch = 10\n",
    "        model_NAG = LinearRegression()\n",
    "        optimizer = optim.SGD(model_HB.parameters(), lr=lamada, momentum=m, weight_decay=0, dampening=0, nesterov=True)\n",
    "        loss_func = nn.MSELoss()\n",
    "        for epoch in range(nEpoch):\n",
    "            for i in range(5): \n",
    "                optimizer.zero_grad()\n",
    "                b_hat = model_NAG(a)\n",
    "                loss = loss_func(b_hat,b)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    b_hat_test = model_NAG(a_test)\n",
    "    loss_func_test = nn.MSELoss()\n",
    "    losses = losses + loss_func_test(b_test,b_hat_test)\n",
    "    losses = losses/100\n",
    "  \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "colab_type": "code",
    "id": "jbKE1MYW3358",
    "outputId": "a219ffcb-2105-4c9c-8fac-d49cc96cab58"
   },
   "outputs": [],
   "source": [
    "lm_set = np.linspace(0.1,1,10)\n",
    "m_set = np.linspace(0.1,1,10)\n",
    "loss_set_HB = np.zeros([10,10])\n",
    "\n",
    "x = 0\n",
    "for i in lm_set:\n",
    "    y = 0\n",
    "    for j in m_set:\n",
    "        loss = ave_loss_HB(i,j)\n",
    "        loss_set_HB[x,y] = loss\n",
    "        #print(x,y)\n",
    "        y += 1\n",
    "    x += 1\n",
    "print(loss_set_HB)\n",
    "np.min(loss_set_HB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "KXfz5AL3jzWs",
    "outputId": "918f328e-6f78-4117-b7f7-5f8060938232"
   },
   "outputs": [],
   "source": [
    "lm_set = np.linspace(0.1,1,10)\n",
    "m_set = np.linspace(0.1,1,10)\n",
    "loss_set_NAG = np.zeros([10,10])\n",
    "\n",
    "x = 0\n",
    "for i in lm_set:\n",
    "    y = 0\n",
    "    for j in m_set:\n",
    "        loss = ave_loss_NAG(i,j)\n",
    "        loss_set_NAG[x,y] = loss\n",
    "        #print(x,y)\n",
    "        y += 1\n",
    "    x += 1\n",
    "print(loss_set_NAG)\n",
    "np.min(loss_set_NAG)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "girdresearch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
